{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banned-cooper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Martial Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64152</td>\n",
       "      <td>39</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61523</td>\n",
       "      <td>50</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95668</td>\n",
       "      <td>38</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25503</td>\n",
       "      <td>53</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75387</td>\n",
       "      <td>28</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>49792</td>\n",
       "      <td>41</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>43800</td>\n",
       "      <td>30</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>54588</td>\n",
       "      <td>30</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>21928</td>\n",
       "      <td>32</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Sales</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>16447</td>\n",
       "      <td>48</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Zip  Age  Education         Martial Status         Occupation   Race  \\\n",
       "0   64152   39  Bachelors          Never-married       Adm-clerical  White   \n",
       "1   61523   50  Bachelors     Married-civ-spouse    Exec-managerial  White   \n",
       "2   95668   38    HS-grad               Divorced  Handlers-cleaners  White   \n",
       "3   25503   53       11th     Married-civ-spouse  Handlers-cleaners  Black   \n",
       "4   75387   28  Bachelors     Married-civ-spouse     Prof-specialty  Black   \n",
       "..    ...  ...        ...                    ...                ...    ...   \n",
       "58  49792   41    HS-grad     Married-civ-spouse       Adm-clerical  White   \n",
       "59  43800   30    HS-grad     Married-civ-spouse  Machine-op-inspct  White   \n",
       "60  54588   30  Bachelors     Married-civ-spouse              Sales  White   \n",
       "61  21928   32    7th-8th  Married-spouse-absent              Sales  White   \n",
       "62  16447   48    HS-grad     Married-civ-spouse   Transport-moving  White   \n",
       "\n",
       "       Sex  \n",
       "0     Male  \n",
       "1     Male  \n",
       "2     Male  \n",
       "3     Male  \n",
       "4   Female  \n",
       "..     ...  \n",
       "58    Male  \n",
       "59    Male  \n",
       "60    Male  \n",
       "61    Male  \n",
       "62    Male  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-progressive",
   "metadata": {},
   "source": [
    "## Task 1 - k-Anonymity and l-Diversity\n",
    "Here we will work with the k-anonymity and a simplified l-diversity mechanisms. We have provided some partial code below for a few different things, and your tasks are to complete a couple of missing functions and answer some questions (See Tasks 1.1-1.4 below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clinical-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple implementation of checking whether a list of quasi-identifiers (as tuples) is k-anonymous \n",
    "def is_k_anonymous(k, list_of_tuples):\n",
    "    c = Counter([\"{}{}{}\".format(t[0], t[1], t[2]) for t in list_of_tuples])\n",
    "    return all([c[ele] >= k for ele in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "activated-trace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will need to create a list of quasi-identifiers to call the above function\n",
    "qis = [(row['Zip'], row['Age'], row['Education']) for index, row in data.iterrows()]\n",
    "is_k_anonymous(2, qis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compact-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The next three functions do different levels of generalization of the sample data, \n",
    "## and can be used to achieve k-anonymity\n",
    "\n",
    "## Generalize zipcode by removing the last few digits\n",
    "## If n is more than the number of digits, then the generalization is to 0\n",
    "def generalize_zipcode(qis, n):\n",
    "    return [(int(r[0]/10**n), r[1], r[2]) for r in qis]\n",
    "\n",
    "## TASK 1.1\n",
    "## You should complete the following two\n",
    "def generalize_age(qis, n):\n",
    "    return qis\n",
    "\n",
    "## TASK 1.2\n",
    "## For generalizing education, we will assume we are provided a mapping dictionary to map the range of\n",
    "## values for that attribute to something smaller\n",
    "def generalize_education(qis, mapping_dict):\n",
    "    return qis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "japanese-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let's try a combination of generalization across the three attributes to see if we achieve k-anonymity\n",
    "### for k = 3\n",
    "modified_qis = generalize_zipcode(qis, 2)\n",
    "modified_qis = generalize_age(modified_qis, 1)\n",
    "\n",
    "education_mapping = {\"11th\": \"No-College\", \"5th-6th\": \"No-College\", \"7th-8th\": \"No-College\", \"9th\": \"No-College\", \"HS-grad\": \"No-College\", \"Bachelors\": \"College\", \"Doctorate\": \"College\", \"Masters\": \"College\", \"Some-college\": \"College\"}\n",
    "modified_qis = generalize_education(modified_qis, education_mapping)\n",
    "\n",
    "is_k_anonymous(2, modified_qis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italian-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1.3\n",
    "### Did the generalizations above achieve 2-anonymity? If not, identify additional generalizations that will \n",
    "### get us to 2-anonymity.\n",
    "### What additional generalization above will allow us to achieve 3-anonymity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hourly-advocacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TASK 1.4\n",
    "# Implement the following simplified diversity check (let's call it x-diversity) where we require that \n",
    "# every group of tuples with the same Quasi-Identifiers has at least x different values of the sensitive attribute\n",
    "# We will further assume that the last attribute in each tuple is the sensitive attribute, and the ones before\n",
    "# are the QIs\n",
    "def is_simplified_x_diverse(x, list_of_tuples):\n",
    "    return False\n",
    "\n",
    "# We can check that the code works with something like this -- here we treat 'race' as the sensitive/hidden attribute\n",
    "qis_and_sensitive = [(row['Zip'], row['Age'], row['Education'], row['Race']) for index, row in data.iterrows()]\n",
    "is_simplified_x_diverse(2, qis_and_sensitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-jewelry",
   "metadata": {},
   "source": [
    "## Task 2: Laplace Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vulnerable-substance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1592429982111556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## np.random has a laplace sampling function\n",
    "np.random.laplace(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expensive-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2.1 -- write a helper function to find the new value for a given sensitivity and epsilon\n",
    "def laplace_noise(v, sensitivity, epsilon):\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jewish-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n",
      "[100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "## Let's try for different values of epsilon and sensitivity\n",
    "## In each case, we will sample 5 times to see the kinds of values we will get in different runs\n",
    "for eps in [0.1, 0.5, 1, 5, 10, 100]:\n",
    "    print([laplace_noise(100, 1, eps) for _ in range(0, 5)])\n",
    "for sensitivity in [1, 5, 10, 50]:\n",
    "    print([laplace_noise(100, sensitivity, 0.5) for _ in range(0, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-lambda",
   "metadata": {},
   "source": [
    "### Task 2.2 \n",
    "Discuss how much noise was added for different values of epsilon and sensitivity, and whether the errors are reasoanble or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-immigration",
   "metadata": {},
   "source": [
    "### Task 2.3 \n",
    "Generate a differentially private histogram over \"Occupation\"\n",
    "Your task is to write the function below to take in a histogram as a dictionary and return a differentially private version of it -- you will have to figure out the right value of sensitivity to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southern-crossing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adm-clerical': 6,\n",
       " 'Exec-managerial': 12,\n",
       " 'Handlers-cleaners': 3,\n",
       " 'Prof-specialty': 9,\n",
       " 'Other-service': 5,\n",
       " 'Sales': 6,\n",
       " 'Craft-repair': 4,\n",
       " 'Transport-moving': 3,\n",
       " 'Farming-fishing': 2,\n",
       " 'Machine-op-inspct': 7,\n",
       " 'Tech-support': 5,\n",
       " 'Protective-serv': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = dict(Counter([row['Occupation'] for index, row in data.iterrows()]))\n",
    "def generate_dp_histogram(hist, epsilon):\n",
    "    return hist\n",
    "generate_dp_histogram(hist, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-memorial",
   "metadata": {},
   "source": [
    "### Task 2.4\n",
    "Let's do the same for a collection of counting queries, with an example shown below.\n",
    "Your task is to write the generate_dp_cq_results -- as above, you will have to figure out the right value of sensitivity to use. The function should not assume that the number of counting queries is fixed, but should use the length of the array as the number of those queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "average-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 16, 10]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting_queries_results = [ data[data['Occupation'] == 'Adm-clerical']['Occupation'].count(), \\\n",
    "                            data[data['Education'] == 'Bachelors']['Occupation'].count(), \\\n",
    "                            data[data['Race'] == 'Black']['Occupation'].count() ]\n",
    "def generate_dp_cq_results(counting_queries_results, epsilon):\n",
    "    return counting_queries_results\n",
    "generate_dp_cq_results(counting_queries_results, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-huntington",
   "metadata": {},
   "source": [
    "## Task 3: Exponential Mechanism\n",
    "Let's walk through an example of the exponential mechanism. We will use this to differentially output the result of query like: \"Which is the most common Occupation\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "considered-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dict(Counter([row['Occupation'] for index, row in data.iterrows()]))\n",
    "## For a given occupation, the utility is defined to be the difference between max count and the count for\n",
    "## that occupation\n",
    "def utility_most_common(hist, occupation):\n",
    "    maximum = max([hist[x] for x in hist])\n",
    "    return hist[occupation] - maximum\n",
    "## Stability here is the absolute difference between min and max counts\n",
    "def stability_most_common(hist):\n",
    "    return max([hist[x] for x in hist]) - min([hist[x] for x in hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legitimate-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adm-Clerical'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your task is to write the following function that generates a differentially private \n",
    "## answer using Exponential Mechanism\n",
    "## The input to this is a Counter like \"hist\" above -- the output should be one of the \n",
    "## words in the Counter (Occupations in this case)\n",
    "## You can use the above two functions for this purpose\n",
    "def generate_dp_answer_most_common(hist, epsilon):\n",
    "    return 'Adm-Clerical'\n",
    "generate_dp_answer_most_common(hist, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-arrangement",
   "metadata": {},
   "source": [
    "## Task 4: Simplified RAPPOR Implementation\n",
    "We will simulate a simplified version of the RAPPOR protocol, using the \"Occupation\" attribute from the data frame above as the sensitive attribute (that the individuals want to hide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "matched-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will use an array of 0's and 1's as a bitstring\n",
    "## Let's use bloom filter length, k = 10\n",
    "## Let's use three hash functions: hash(s + \"one\"), hash(s + \"two\"), hash(s + \"three\")\n",
    "BLOOM_FILTER_LENGTH = 10\n",
    "PROB_PERM_RESPONSE = 0.75\n",
    "PROB_INSTA_RESPONSE = 0.75\n",
    "\n",
    "## Construct the bloom filter for a string\n",
    "def bloom_filter(s):\n",
    "    ret = [0 for _ in range(0, BLOOM_FILTER_LENGTH)]\n",
    "    ret[hash(s + \"one\")%BLOOM_FILTER_LENGTH] = 1\n",
    "    ret[hash(s + \"two\")%BLOOM_FILTER_LENGTH] = 1    \n",
    "    ret[hash(s + \"three\")%BLOOM_FILTER_LENGTH] = 1\n",
    "    return ret\n",
    "\n",
    "def randomized_response(act_value, prob):\n",
    "    if random.random() < prob:\n",
    "        return act_value\n",
    "    return 1 - act_value   ## return 0 if act_value = 1 and vice versa\n",
    "\n",
    "### Permanent responses are different for each user who is contributing data\n",
    "perm_responses_by_user = [dict() for _ in range(0, 100)]\n",
    "\n",
    "def perm_response(s, userindex):\n",
    "    if not s in perm_responses_by_user[userindex]:\n",
    "        bf = bloom_filter(s)\n",
    "        for index in range(0, len(bf)):\n",
    "            bf[index] = randomized_response(bf[index], PROB_PERM_RESPONSE)\n",
    "        perm_responses_by_user[userindex][s] = bf\n",
    "    return perm_responses_by_user[userindex][s]\n",
    "\n",
    "## Obtain the instantenous response for a string for a user, by first getting the perm_response and then \n",
    "## randomizing it\n",
    "def insta_response(s, userindex):\n",
    "    bf_ir = [x for x in perm_response(s, userindex)]\n",
    "    for index in range(0, len(bf_ir)):\n",
    "        bf_ir[index] = randomized_response(bf_ir[index], PROB_INSTA_RESPONSE)\n",
    "    return bf_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "final-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original [1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "Permanent responses\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "Instateneous responses\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "[1, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "## We can confirm that perm_response for a given string, userindex combination is always the same\n",
    "print(\"Original {}\".format(bloom_filter(\"Adm-clerical\")))\n",
    "print(\"Permanent responses\")\n",
    "for i in range(0, 5):\n",
    "    print(perm_response(\"Adm-clerical\", 0))\n",
    "## But insta_response is not\n",
    "print(\"Instateneous responses\")\n",
    "for i in range(0, 5):\n",
    "    print(insta_response(\"Adm-clerical\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adopted-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's simulate a full run of a simplified version of RAPPOR\n",
    "### We will assume we have 10 users, who each are producing a collection of strings\n",
    "### For each of their strings, each user will return an instantenous response\n",
    "\n",
    "### Let's create the data\n",
    "### by picking a random subset from the data frame above as the data for each user\n",
    "### For repeatability, we will set the seed here\n",
    "random.seed(100)\n",
    "user_data = []\n",
    "for i in range(0, 10):\n",
    "    user_data.append([])\n",
    "    for index, row in data.iterrows():\n",
    "        if random.random() < 0.6:\n",
    "            user_data[i].append(row['Occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "close-transformation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Adm-clerical': 50,\n",
       "         'Exec-managerial': 60,\n",
       "         'Handlers-cleaners': 20,\n",
       "         'Prof-specialty': 60,\n",
       "         'Other-service': 10,\n",
       "         'Sales': 40,\n",
       "         'Transport-moving': 10,\n",
       "         'Farming-fishing': 10,\n",
       "         'Tech-support': 40,\n",
       "         'Craft-repair': 10,\n",
       "         'Protective-serv': 10,\n",
       "         'Machine-op-inspct': 50})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Our end goal here is to collect a histogram over all the strings in the user_data\n",
    "### in a privacy-preserving manner\n",
    "### Here is the correct answer, i.e., \"Ground Truth\" so to say\n",
    "ground_truth = Counter([x for x in user_data[i] for i in range(0, 10)])\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "retired-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 1, 0, 0, 1, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n",
       " [0, 0, 0, 0, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 1, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [1, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 0, 1, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 1, 0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The \"collector\" (who is untrusted in this case) only gets to see the \"insta_responses\"\n",
    "collected_data = []\n",
    "for i in range(0, 10):\n",
    "    for x in user_data[i]:\n",
    "        collected_data.append(insta_response(x, i))\n",
    "collected_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-island",
   "metadata": {},
   "source": [
    "### Task 4.1\n",
    "You have to implement the \"recovery\" portion using a simpler approach than what RAPPOR did\n",
    "- Step 1: Sum up all the collected bloom filters to get a single vector of size 10\n",
    "- Step 2: Scale the observed numbers based on the probabilities we are using \n",
    "- Step 3: Find the best vector over input strings that matches the output we see using a regression package\n",
    "\n",
    "We have done Step 3 below, but you have to implement Steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "illegal-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_scaling_factor(prob1, prob2):\n",
    "    return 1\n",
    "def find_sum_vector(collected_data):\n",
    "    return [0 for _ in range(0, 10)]\n",
    "\n",
    "sum_vector = find_sum_vector(collected_data)\n",
    "scaling_factor = find_scaling_factor(0.75, 0.75) ### These are the two probabilities we use above\n",
    "scaled_sum_vector = [x * scaling_factor for x in sum_vector]\n",
    "\n",
    "### We can now construct design matrix X\n",
    "all_occupations = set([row['Occupation'] for index, row in data.iterrows()])\n",
    "X = [bloom_filter(x) for x in all_occupations]\n",
    "estimated_counts = [0 for _ in range(0, 10)]\n",
    "\n",
    "### We are looking for the estimated_counts vector that best matches the scaled_sum_vector that we saw\n",
    "### In other words, we want X * estimated_counts to be as close to scaled_sum_vector as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alpha-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We can use the linear algebra package least squared algorithm to find the best fit\n",
    "np.linalg.lstsq(np.array(X).T, np.array(scaled_sum_vector))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-bikini",
   "metadata": {},
   "source": [
    "### Task 4.2\n",
    "Discuss how well the answers matched the above answers. Regenerate the \"collected answers\" (so that you would be using different randomization for insta_responses) and discuss what impact it had on the estimated answers.\n",
    "\n",
    "You can write your answer in the next empty cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-producer",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
